{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wa8ykQk92aLX"
   },
   "source": [
    "# Evaluation with RAGAS and Advanced Retrieval Methods Using LangChain\n",
    "\n",
    "In the following notebook we'll discuss a major component of LLM Ops:\n",
    "\n",
    "- Evaluation\n",
    "\n",
    "We're going to be leveraging the [RAGAS]() framework for our evaluations today as it's becoming a standard method of evaluating (at least directionally) RAG systems.\n",
    "\n",
    "We're also going to discuss a few more powerful Retrieval Systems that can potentially improve the quality of our generations!\n",
    "\n",
    "Let's start as we always do: Grabbing our dependencies!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Lhqp5rUThG-",
    "outputId": "c33f7eee-b819-40bd-dc75-ce90721a6a94"
   },
   "outputs": [],
   "source": [
    "import os\n",
    "import openai\n",
    "from langchain_community.document_loaders import PyPDFLoader\n",
    "from werkzeug.utils import secure_filename\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "from langchain.schema import Document\n",
    "from elasticsearch import Elasticsearch\n",
    "from langchain_elasticsearch import ElasticsearchStore\n",
    "from langchain_google_genai import GoogleGenerativeAIEmbeddings\n",
    "from langchain.vectorstores import Chroma\n",
    "from langchain.embeddings import OpenAIEmbeddings\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "import logging\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain.text_splitter import RecursiveCharacterTextSplitter\n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain.text_splitter import MarkdownHeaderTextSplitter\n",
    "\n",
    "\n",
    "\n",
    "es_cloud_id=\"My_deployment:YXAtc291dGgtMS5hd3MuZWxhc3RpYy1jbG91ZC5jb20kNjg1M2ZlMjBhZjljNDEzNTk4Y2E4Yzc4Y2Q0Y2EzMWEkM2M5NGQwNDY3ODQ5NDE1Yzk1MWVjN2I2NjI4ZjJmZTc=\"\n",
    "es_api_key=\"bE9tVmM1RUJEOVhTWGU2ckhTSlk6dU9URldzSHVSVXVnRW9fNkJGMW5nZw==\"\n",
    "client=Elasticsearch(cloud_id=es_cloud_id,api_key=es_api_key)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "DTDNFXaBSO2j",
    "outputId": "3b24521d-5c6f-466b-d818-46ce68d359ee"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "4"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#loader\n",
    "loader = PyPDFLoader(\"env.pdf\")\n",
    "docs = loader.load()\n",
    "len(docs)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nNPAWPgNSyGP",
    "outputId": "b2f80fc8-792c-489a-b8d4-9f98678c679a"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'source': 'env.pdf', 'page': 0}\n",
      "{'source': 'env.pdf', 'page': 1}\n",
      "{'source': 'env.pdf', 'page': 2}\n",
      "{'source': 'env.pdf', 'page': 3}\n"
     ]
    }
   ],
   "source": [
    "for doc in docs:\n",
    "  print(doc.metadata)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Z7ht6bJX9PAY"
   },
   "source": [
    "### Creating an Index\n",
    "\n",
    "Let's use a naive index creation strategy of just using `RecursiveCharacterTextSplitter` on our documents and embedding each into our `VectorStore` using `OpenAIEmbeddings()`.\n",
    "\n",
    "- [`RecursiveCharacterTextSplitter()`](https://api.python.langchain.com/en/latest/text_splitter/langchain.text_splitter.RecursiveCharacterTextSplitter.html)\n",
    "- [`Chroma`](https://api.python.langchain.com/en/latest/vectorstores/langchain.vectorstores.chroma.Chroma.html?highlight=chroma#langchain.vectorstores.chroma.Chroma)\n",
    "- [`OpenAIEmbeddings()`](https://api.python.langchain.com/en/latest/embeddings/langchain.embeddings.openai.OpenAIEmbeddings.html?highlight=openaiembeddings#langchain-embeddings-openai-openaiembeddings)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {
    "id": "xne8P5dQTUiR",
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "openai_api_key=\"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\"\n",
    "\n",
    "def get_hierarchical_chunks(pages):\n",
    "    headers_to_split_on = [\n",
    "        (\"#\", \"Header 1\"),\n",
    "        (\"##\", \"Header 2\"),\n",
    "        (\"###\", \"Header 3\"),\n",
    "    ]\n",
    "    markdown_splitter = MarkdownHeaderTextSplitter(headers_to_split_on=headers_to_split_on)\n",
    "    \n",
    "    final_chunks = []\n",
    "    for page in pages:\n",
    "        md_header_splits = markdown_splitter.split_text(page.page_content)\n",
    "        \n",
    "        text_splitter = RecursiveCharacterTextSplitter(\n",
    "            chunk_size=2000,\n",
    "            chunk_overlap=400,\n",
    "            length_function=len,\n",
    "            separators=[\"\\n\\n\", \"\\n\", \" \", \"\"]\n",
    "        )\n",
    "\n",
    "        for doc in md_header_splits:\n",
    "            smaller_chunks = text_splitter.split_text(doc.page_content)\n",
    "            for chunk in smaller_chunks:\n",
    "                final_chunks.append(Document(\n",
    "                    page_content=chunk,\n",
    "                    metadata={\n",
    "                        \"source\": page.metadata.get(\"source\", \"\"),\n",
    "                        \"page\": page.metadata.get(\"page\", \"\"),\n",
    "                        \"header\": \" > \".join([doc.metadata.get(f\"Header {i}\", \"\") for i in range(1, 4) if f\"Header {i}\" in doc.metadata])\n",
    "                    }\n",
    "                ))\n",
    "\n",
    "    return final_chunks\n",
    "\n",
    "def create_index_with_mapping(index_name):\n",
    "    mapping = {\n",
    "        \"mappings\": {\n",
    "            \"properties\": {\n",
    "                \"vector\": {\n",
    "                    \"type\": \"dense_vector\",\n",
    "                    \"dims\": 1536 \n",
    "                },\n",
    "                \"content\": {\n",
    "                    \"type\": \"text\"\n",
    "                },\n",
    "                \"keyword_content\": {\n",
    "                    \"type\": \"keyword\"\n",
    "                }\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "    # Create the index with the specified mapping\n",
    "    if elastic_search_client.indices.exists(index=index_name):\n",
    "        elastic_search_client.indices.delete(index=index_name)\n",
    "    elastic_search_client.indices.create(index=index_name, body=mapping)\n",
    "    logging.info(f\"Index '{index_name}' with custom mapping created successfully.\")\n",
    "\n",
    "def get_text_chunks(pages, user_session):\n",
    "    # Assuming `pages` is a list of Document objects, each representing a page of the document\n",
    "    all_chunks = []\n",
    "\n",
    "    # Iterate over each page and apply hierarchical chunking\n",
    "    full_text = \"\"\n",
    "    for page in pages:\n",
    "        # Get hierarchical chunks\n",
    "        hierarchical_chunks = get_hierarchical_chunks([page])\n",
    "        all_chunks.extend(hierarchical_chunks)\n",
    "        full_text += page.page_content\n",
    "    \n",
    "    if not os.path.exists(user_session):\n",
    "        os.makedirs(user_session)\n",
    "    filename = f'{user_session}/content.txt'\n",
    "    with open(filename, \"w\") as file:\n",
    "        file.write(full_text)\n",
    "    \n",
    "    return all_chunks\n",
    "\n",
    "docss = get_text_chunks(docs, 'surya')\n",
    "\n",
    "def elastic_store(docs, user_session):\n",
    "    create_index_with_mapping(user_session)\n",
    "    db = ElasticsearchStore.from_documents(\n",
    "    docs,\n",
    "    es_cloud_id=es_cloud_id,\n",
    "        index_name=user_session,\n",
    "            es_api_key=es_api_key\n",
    "                )\n",
    "\n",
    "def get_vector_store(text_chunks, usersession):\n",
    "    try:\n",
    "        logging.info('creating vector store')\n",
    "        embeddings = OpenAIEmbeddings(api_key=openai_api_key)\n",
    "        logging.info('embedding model chosen')\n",
    "        vector_store = ElasticsearchStore(\n",
    "    index_name=str(usersession), embedding=embeddings, es_cloud_id=es_cloud_id, es_api_key=es_api_key,vector_query_field=\"vector\"\n",
    ")\n",
    "        vector_store.add_documents(text_chunks)\n",
    "    except Exception as e:\n",
    "        logging.info(e)\n",
    "        raise\n",
    "        \n",
    "def store_vector(raw_text, user_session):\n",
    "    text_chunks = get_text_chunks(raw_text, user_session)\n",
    "    logging.info('text converted to chunks')\n",
    "\n",
    "    # Store Elastic Search index\n",
    "    if client.indices.exists(index=user_session):\n",
    "        client.indices.delete(index=user_session)\n",
    "        logging.info(f\"Index '{user_session}' deleted.\")\n",
    "        client.indices.create(index=user_session)\n",
    "    logging.info(f\"Index '{user_session}' created successfully.\")\n",
    "    # elastic_store(text_chunks, user_session)\n",
    "    get_vector_store(text_chunks, user_session)\n",
    "    logging.info(\"Chunks stored to Elastic Search\")\n",
    "\n",
    " \n",
    "\n",
    "store_vector(docss, 'surya')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 82,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "cnRzYx4c_2mZ",
    "outputId": "59d9bdd8-0414-4e8b-c285-bf3a2760e26a"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 82,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(docss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "WyUh8EVI_6TZ",
    "outputId": "643fca9d-77c0-4296-d953-ec62d6de8954"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1991\n"
     ]
    }
   ],
   "source": [
    "print(max([len(chunk.page_content) for chunk in docss]))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0f9kNIUUTxdT"
   },
   "source": [
    "Let's convert our `Chroma` vectorstore into a retriever with the `.as_retriever()` method."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_elasticsearch.retrievers import ElasticsearchRetriever\n",
    "from langchain.retrievers import EnsembleRetriever\n",
    "from elasticsearch import Elasticsearch\n",
    "from langchain.chains.question_answering import load_qa_chain\n",
    "from langchain.prompts import PromptTemplate\n",
    "from langchain_community.chat_models import ChatOllama \n",
    "from langchain_community.embeddings import OllamaEmbeddings\n",
    "from langchain_community.vectorstores.faiss import FAISS\n",
    "from langchain.retrievers.multi_query import MultiQueryRetriever\n",
    "import json\n",
    "import requests\n",
    "import logging\n",
    "import time\n",
    "from langchain_google_genai.chat_models import ChatGoogleGenerativeAI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 85,
   "metadata": {},
   "outputs": [],
   "source": [
    "def keyword_body_func(query):\n",
    "    return {\n",
    "        \"query\": {\n",
    "            \"match\": {\n",
    "                \"text\": query\n",
    "            }\n",
    "        },\n",
    "        \"_source\": {\n",
    "            \"includes\": [\"text\"]\n",
    "        }\n",
    "    }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {
    "id": "bwbdftltT29h"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[Document(metadata={'source': 'env.pdf', 'page': 2, 'header': ''}, page_content='Magsaysay awardee Sh. Rajender Singh  known for his water conservation efforts are some such contemporary\\nfigures. Salim Ali  is a renowned ornithologist, famous for his work on Indian birds. In modern India, our late\\nPrime Minister Mrs. Indira Gandhi was instrumental in introducing the concept of environmental protection in\\nthe Constitution of India as a fundamental duty while Mrs. Maneka Gan dhi, formerly environment minister, has\\nworked a lot for the cause of wildlife protection. Citizen’s report on environment  was first published by late\\nSh. Anil Aggarwal , the founder Chairman of Centre for Science & Environment. Even with many such key\\npersons leading the cause to environment, India is yet to achieve a lot in this field.'),\n",
       " Document(metadata={'source': 'env.pdf', 'page': 3, 'header': ''}, page_content='(d) Role of Government, Concept of Ecomark: In order to increase consumer awareness about environment,\\nthe Government of India has introduced a scheme of ecolabelling of consumer products as ‘Ecomark’ in 1991. It\\nis an ‘earthen pitcher’ –a symbol of eco -friendliness and our traditional heritage. A product that is made, used or\\ndisposed off in a harmless manner is called eco -friendly and is awarded this eco -mark.  In a dr ive to disseminate\\nenvironmental awareness ‘Eco -Clubs’ for children and ‘Eco -task force’ for army men have also been launched\\nby the government.'),\n",
       " Document(metadata={'source': 'env.pdf', 'page': 1, 'header': ''}, page_content='Environment Calendar\\nNEED FOR PUBLIC AWARENESS\\n(a) International Efforts for Environment\\nEnvironmental issues received international attention about 35 years back in Stockholm Conference, held on 5th\\nJune, 1972. Since then we celebrate World Environment Day on 5th June. At the United Nations Conference\\non Environment and Development held at Ri o de Janeiro, in 1992, known popularly as Earth Summit, and ten\\nyears later, the World Summit on Sustainable Development, held at Johannesburg in 2002, key issues of global\\nenvironmental concern were highlighted. Attention of general public was drawn towards the deteriorating\\nenvironmental conditions all over the world.'),\n",
       " Document(metadata={'source': 'env.pdf', 'page': 0, 'header': ''}, page_content='Environmental studies can also be highly specialized concentrating on more technical aspects like environmental\\nscience, environmental engineering or environmental management. In the recent years, the scope of environmental\\nstudies h as expanded dramatically the world over. Several career options have emerged in this field that is broadly\\ncategorized as:\\n(i) Research & Development (R & D) in environment: Skilled environmental scientists have an important role\\nto play in examining vari ous environmental problems in a scientific manner and carry out R & D activities for\\ndeveloping cleaner technologies and promoting sustainable development.\\n(ii) Green advocacy: With increasing emphasis on implementing various Acts and Laws related to environment,\\nneed for environmental lawyers has emerged, who should be able to plead the cases related to water and air\\npollution, forest, wildlife etc.\\n(iii) Green marketing: While ensuring the quality of products with ISO mark, now there is an increasing\\nemphasis on marketing goods that are environment friendly. Such products have ecomark or ISO 14000\\ncertification. Environmental auditors and environmental managers would be in great demand in the coming years.\\nChapter 1 – Introduction to Environment')]"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "es_weight = 0.5\n",
    "vector_weight = 0.6\n",
    "weights = [es_weight,vector_weight]\n",
    "keyret = ElasticsearchRetriever(es_client=client, index_name=\"surya\", body_func=keyword_body_func, content_field=\"text\")\n",
    "embeddings=OpenAIEmbeddings(api_key=openai_api_key)\n",
    "vdb = ElasticsearchStore(\n",
    "        es_cloud_id=es_cloud_id,\n",
    "        es_api_key=es_api_key,\n",
    "        index_name=\"surya\",\n",
    "        embedding=embeddings,\n",
    "    )\n",
    "vector_ret = vdb.as_retriever()\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[keyret, vector_ret], weights=weights)\n",
    "docs = ensemble_retriever.get_relevant_documents(\"hello\", k=6)\n",
    "docs"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "DBPZQUt4UBPl"
   },
   "source": [
    "Now to give it a test!"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "D8MKsT6JTgCU"
   },
   "source": [
    "## Creating a Retrieval Augmented Generation Prompt\n",
    "\n",
    "Now we can set up a prompt template that will be used to provide the LLM with the necessary contexts, user query, and instructions!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {
    "id": "ijSNkTAjTsep"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "template = prompt_template = \"\"\"\n",
    "Answer the question as detailed as possible but only on the provided context.  Review the chat history carefully to provide all necessary details and avoid incorrect information. Treat synonyms or similar words as equivalent within the context. For example, if a question refers to \"modules\" or \"units\" instead of \"chapters\" or \"doc\" instead of \"document\" consider them the same. \n",
    "If the question is not related to the provided context, simply respond that the question is out of context and instead provide a summary of the document and example questions that the user can ask.\n",
    "Do not make up an answer if the provided question is not within the context. Instead, provide example questions that the user can ask and summary of the document.\n",
    "Do not repeat facts in the answer if you have already stated them. \n",
    "If the question is short, like it is asking for the dates, names or requires a very short answer then keep the response short and to the point. \n",
    "If the question asks for a particular keyword that is in context, state information related to that keyword. \n",
    "Example: Question : When was bill gates born?\n",
    "Answer: According to the documents you have uploaded, bill gates was born in 1989. \n",
    "However, if the question requires a detailed answer, then consider all possibiliies related to the question and try to answer in Bullet points and clear and concise paragraphs. \n",
    "If asked to summarise the document, try to provide a basic summary of the entire context and cover it in bullet points but keep the answer concise and not too long. \n",
    "If the question mention 'what are the contents of the file' or asks about the uploaded document or anything similar, just cover the entire document as a summary.\n",
    "VERY IMPORTANT State the source in the end along with the answer but dont state the source if the question is out of context.\n",
    "If the source is like : temp/abc.docx, then just mention the file name like abc.docx.\n",
    "In the beginning of the anser, always mention the exact line in quotation marks that is being referred to in the answer and enclose it within **bold** tags.\n",
    "Example : \"According to the document in the line \"The company was started in 1990\", to answer your question(state the query in a shorter and concise manner), the company was founded in 1990.\"\n",
    "Highlight Key Points: Enclose each identified key point within `**bold**` tags.\n",
    "Highlight Keywords: Enclose each identified keyword within `*italic*` tags.\n",
    "Documents:\\n{context}\\n\n",
    "Question:\\n{question}\\n\n",
    "Answer:\n",
    "\"\"\"\n",
    "\n",
    "\n",
    "prompt = PromptTemplate(template=prompt_template, input_variables=[\"context\", \"question\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "BYHnPaXl-cvJ"
   },
   "source": [
    "### Setting Up our Basic QA Chain\n",
    "\n",
    "Now we can instantiate our basic RAG chain!\n",
    "\n",
    "We'll follow *exactly* the chain we made on Tuesday to keep things simple for now - if you need a refresher on what it looked like - check out last week's notebook!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {
    "id": "-TsjUWjbUfbW"
   },
   "outputs": [],
   "source": [
    "from operator import itemgetter\n",
    "\n",
    "from langchain.chat_models import ChatOpenAI\n",
    "from langchain.schema.output_parser import StrOutputParser\n",
    "from langchain.schema.runnable import RunnableLambda, RunnablePassthrough\n",
    "\n",
    "model = ChatOllama(temperature=0.2, model=\"llama3.1:70b\", top_p=0.5, top_k=10)\n",
    "\n",
    "retrieval_augmented_qa_chain = (\n",
    "    # INVOKE CHAIN WITH: {\"question\" : \"<<SOME USER QUESTION>>\"}\n",
    "    # \"question\" : populated by getting the value of the \"question\" key\n",
    "    # \"context\"  : populated by getting the value of the \"question\" key and chaining it into the base_retriever\n",
    "    {\"context\": itemgetter(\"question\") | ensemble_retriever, \"question\": itemgetter(\"question\")}\n",
    "    # \"context\"  : is assigned to a RunnablePassthrough object (will not be called or considered in the next step)\n",
    "    #              by getting the value of the \"context\" key from the previous step\n",
    "    | RunnablePassthrough.assign(context=itemgetter(\"context\"))\n",
    "    # \"response\" : the \"context\" and \"question\" values are used to format our prompt object and then piped\n",
    "    #              into the LLM and stored in a key called \"response\"\n",
    "    # \"context\"  : populated by getting the value of the \"context\" key from the previous step\n",
    "    | {\"response\": prompt | model, \"context\": itemgetter(\"context\")}\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "zO69de-F-oMD"
   },
   "source": [
    "Let's test it out!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "2FS5NxC6UyU2",
    "outputId": "2520bf73-9e62-435c-a213-c26d0655a913"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'response': AIMessage(content='The text does not provide a clear definition of \"the environment\". However, based on the context, it appears to refer to the natural world and the ecosystem that supports life on Earth. The text discusses various environmental issues, such as conservation, sustainability, and pollution, which suggests that the environment is being referred to in a broad sense, encompassing both the physical and biological components of the planet.', additional_kwargs={}, response_metadata={'model': 'llama3.1:70b', 'created_at': '2024-10-01T08:16:59.520399287Z', 'message': {'role': 'assistant', 'content': ''}, 'done_reason': 'stop', 'done': True, 'total_duration': 7427899296, 'load_duration': 46558995, 'prompt_eval_count': 1026, 'prompt_eval_duration': 1999729000, 'eval_count': 80, 'eval_duration': 5329826000}, id='run-176b9187-40df-4e30-9fc3-075029654f5c-0'), 'context': [Document(metadata={'_index': 'surya', '_id': '59f898e9-fc26-4fbf-ae0a-1c47725caee3', '_score': 0.25287822, '_ignored': ['text.keyword'], '_source': {}}, page_content='‘Environment’ is a term derived from the Latin word ‘Environ’ that means ‘to surround’.  As per Environment\\n(Protection) Act, 1986, environment includes all the physical and biological surroundings of an organism along\\nwith their interactions. Environment is thus defined as “the sum  total of water, air and land and the inter -\\nrelationships that exist among them and with the human  beings, other living organisms and materials.”\\nThe concept of environment can be clearly understood from Fig 1. It depicts the e nvironment of human beings.\\nAir, water and land surrounding us constitute our environment, and influence us directly. At the same time we too\\nhave an influence on our environment due to overuse or over -exploitation of resources  or due to discharge of\\npollutants in the air, water and land. The flora, fauna and micro -organisms as well as the man -made structures in\\nour surroundings have a bi -directional interaction with us directly or indirectly. The totality of all these\\ncomponents and their interactions con stitute the environment.\\nSCOPE\\nEnvironmental studies as a subject has a wide scope. It encompasses a large number of areas and aspects, which\\nmay be summarized as follows:\\n• Natural resources —their conservation and management\\n• Ecology and biodiversity\\n• Environmental pollution and control\\n• Social issues in relation to development and environment\\n• Human population and environment\\nThese are the basic aspects of environmental studies which have a direct relevance to every s ection of the society.\\nEnvironmental studies can also be highly specialized concentrating on more technical aspects like environmental\\nscience, environmental engineering or environmental management. In the recent years, the scope of environmental\\nstudies h as expanded dramatically the world over. Several career options have emerged in this field that is broadly\\ncategorized as:'), Document(metadata={'_index': 'surya', '_id': '647e60ab-fbff-4d58-bdc1-cd7b1a09c4e7', '_score': 0.239432, '_ignored': ['text.keyword'], '_source': {}}, page_content='Environment Calendar\\nNEED FOR PUBLIC AWARENESS\\n(a) International Efforts for Environment\\nEnvironmental issues received international attention about 35 years back in Stockholm Conference, held on 5th\\nJune, 1972. Since then we celebrate World Environment Day on 5th June. At the United Nations Conference\\non Environment and Development held at Ri o de Janeiro, in 1992, known popularly as Earth Summit, and ten\\nyears later, the World Summit on Sustainable Development, held at Johannesburg in 2002, key issues of global\\nenvironmental concern were highlighted. Attention of general public was drawn towards the deteriorating\\nenvironmental conditions all over the world.'), Document(metadata={'_index': 'surya', '_id': 'c2a26cf3-3b92-47f2-bc44-f1c67a840e1a', '_score': 0.23223855, '_ignored': ['text.keyword'], '_source': {}}, page_content='Environmental studies can also be highly specialized concentrating on more technical aspects like environmental\\nscience, environmental engineering or environmental management. In the recent years, the scope of environmental\\nstudies h as expanded dramatically the world over. Several career options have emerged in this field that is broadly\\ncategorized as:\\n(i) Research & Development (R & D) in environment: Skilled environmental scientists have an important role\\nto play in examining vari ous environmental problems in a scientific manner and carry out R & D activities for\\ndeveloping cleaner technologies and promoting sustainable development.\\n(ii) Green advocacy: With increasing emphasis on implementing various Acts and Laws related to environment,\\nneed for environmental lawyers has emerged, who should be able to plead the cases related to water and air\\npollution, forest, wildlife etc.\\n(iii) Green marketing: While ensuring the quality of products with ISO mark, now there is an increasing\\nemphasis on marketing goods that are environment friendly. Such products have ecomark or ISO 14000\\ncertification. Environmental auditors and environmental managers would be in great demand in the coming years.\\nChapter 1 – Introduction to Environment'), Document(metadata={'_index': 'surya', '_id': '281b8dfa-8976-4410-86d8-7b4100a115ee', '_score': 0.21567042, '_ignored': ['text.keyword'], '_source': {}}, page_content='(iv) Green media: Environmental awareness ca n be spread amongst masses through mass media like television,\\nradio, newspaper, magazines, hoardings, advertisements etc. for which environmentally educated persons are\\nrequired.\\n(v) Environment consultancy: Many non -government organizations (NGOs), indu stries and government bodies\\nare engaging environmental consultants for systematically studying and tackling environment related problems.\\nIMPORTANCE OF ENVIRONMENT\\n(a) Global vs. Local Importance of Environment: Environment is one subject that is actuall y global as well as\\nlocal in nature.  Issues like global warming, depletion of ozone layer, dwindling forests and energy resources,  loss\\nof global biodiversity etc. which are going to affect the mankind as a whole are global in nature and  for that we\\nhave t o think and plan globally.\\nHowever, there are some environmental problems which are of localized importance. For dealing with local\\nenvironmental issues, e.g. impact of mining or hydroelectric project in an area, problems of disposal and\\nmanagement of soli d waste, river or lake pollution, soil erosion, water logging and salinization of soil, fluorosis\\nproblem in local population, arsenic pollution of groundwater etc., we have to think and act locally.\\n(b) Individualistic Importance of Environment Environme ntal studies is very important since it deals with the\\nmost mundane problems of life  where each individual matters, like dealing with safe and clean drinking water,\\nhygienic living conditions,  clean and fresh air, fertile land, healthy food and sustainable  development.\\nEnvironment Calendar\\nNEED FOR PUBLIC AWARENESS\\n(a) International Efforts for Environment\\nEnvironmental issues received international attention about 35 years back in Stockholm Conference, held on 5th\\nJune, 1972. Since then we celebrate World Environment Day on 5th June. At the United Nations Conference'), Document(metadata={'_index': 'surya', '_id': 'ed3c6f35-916d-4690-970a-d1c9e99eac34', '_score': 0.23989776, '_ignored': ['text.keyword'], '_source': {}}, page_content='Magsaysay awardee Sh. Rajender Singh  known for his water conservation efforts are some such contemporary\\nfigures. Salim Ali  is a renowned ornithologist, famous for his work on Indian birds. In modern India, our late\\nPrime Minister Mrs. Indira Gandhi was instrumental in introducing the concept of environmental protection in\\nthe Constitution of India as a fundamental duty while Mrs. Maneka Gan dhi, formerly environment minister, has\\nworked a lot for the cause of wildlife protection. Citizen’s report on environment  was first published by late\\nSh. Anil Aggarwal , the founder Chairman of Centre for Science & Environment. Even with many such key\\npersons leading the cause to environment, India is yet to achieve a lot in this field.'), Document(metadata={'_index': 'surya', '_id': 'eb98d8ba-015d-4a45-b1ae-3acc31c8fe43', '_score': 0.23061812, '_ignored': ['text.keyword'], '_source': {}}, page_content='_\\n(b) Public Awareness for Environment\\nThe goals of  sustainable development cannot be achieved by any government at its own level until the public has\\na participatory role in it. Public participation is possible only when the public is aware about the ecological and\\nenvironmental issues. The public has to be educated about the fact that if we are degrading our environment we\\nare actually harming our own selves.\\n(c) Role of Contemporary Indian Environmentalists in Environmental Awareness\\nIn our country, efforts to raise environmental awareness have been in itiated, and several landmark judgments\\nrelated to environmental litigations have highlighted the importance of this subject to general public. Two noted\\npersonalities, who need a mention here, are Justice Kuldeep Singh, known popularly as the green judge and Sh.\\nM.C. Mehta, the green advocate, who have immensely contributed to the cause of environment.\\nIn 1991, the Supreme Court of our country issued directives to make all curricula\\nEnvironment -oriented. This directive was, in fact, in response to a Public Interest Litigation (PIL) filed by M.C.\\nMehta vs. Union of India (1988) that prompted the apex court to give a mandate for creating environmental\\nawareness among all citizens of India. Based on the judgm ent, Environmental Studies is being taught as a\\ncompulsory course to all students.\\nThere are some environmentalists in the present time who have made a mark in our country\\nthrough environmental activism. Sh. Sunderlal Bahuguna , known for his ‘Chipko moveme nt’ and ‘Tehri Bachao\\nAndolan’, Smt. Medha Patkar  and Ms. Arundhati Roy  known for their ‘Narmada Bachao Andolan’, the\\nMagsaysay awardee Sh. Rajender Singh  known for his water conservation efforts are some such contemporary\\nfigures. Salim Ali  is a renowned ornithologist, famous for his work on Indian birds. In modern India, our late\\nPrime Minister Mrs. Indira Gandhi was instrumental in introducing the concept of environmental protection in'), Document(metadata={'_index': 'surya', '_id': '7977a1ac-d29c-42d4-886d-ce4250ecad3c', '_score': 0.18807563, '_ignored': ['text.keyword'], '_source': {}}, page_content='(d) Role of Government, Concept of Ecomark: In order to increase consumer awareness about environment,\\nthe Government of India has introduced a scheme of ecolabelling of consumer products as ‘Ecomark’ in 1991. It\\nis an ‘earthen pitcher’ –a symbol of eco -friendliness and our traditional heritage. A product that is made, used or\\ndisposed off in a harmless manner is called eco -friendly and is awarded this eco -mark.  In a dr ive to disseminate\\nenvironmental awareness ‘Eco -Clubs’ for children and ‘Eco -task force’ for army men have also been launched\\nby the government.')]}\n"
     ]
    }
   ],
   "source": [
    "question = \"whats the environment\"\n",
    "\n",
    "result = retrieval_augmented_qa_chain.invoke({\"question\" : question})\n",
    "\n",
    "print(result)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wyazkAIu85KL"
   },
   "source": [
    "### Ground Truth Dataset Creation Using GPT-3.5-turbo and GPT-4\n",
    "\n",
    "The next section might take you a long time to run, so the evaluation dataset is provided.\n",
    "\n",
    "The basic idea is that we can use LangChain to create questions based on our contexts, and then answer those questions.\n",
    "\n",
    "Let's look at how that works in the code!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {
    "id": "V24T_gpPatAO"
   },
   "outputs": [],
   "source": [
    "from langchain.output_parsers import ResponseSchema\n",
    "from langchain.output_parsers import StructuredOutputParser\n",
    "\n",
    "question_schema = ResponseSchema(\n",
    "    name=\"question\",\n",
    "    description=\"a question about the context.\"\n",
    ")\n",
    "\n",
    "question_response_schemas = [\n",
    "    question_schema,\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 92,
   "metadata": {
    "id": "ebbmazGrdPap"
   },
   "outputs": [],
   "source": [
    "question_output_parser = StructuredOutputParser.from_response_schemas(question_response_schemas)\n",
    "format_instructions = question_output_parser.get_format_instructions()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "id": "qorL4TPGXJQ7"
   },
   "outputs": [],
   "source": [
    "question_generation_llm = ChatOpenAI(model=\"gpt-4o\", api_key=openai_api_key)\n",
    "\n",
    "bare_prompt_template = \"{content}\"\n",
    "bare_template = ChatPromptTemplate.from_template(template=bare_prompt_template)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {
    "id": "oPqC1_MXdRuh"
   },
   "outputs": [],
   "source": [
    "from langchain.prompts import ChatPromptTemplate\n",
    "\n",
    "qa_template = \"\"\"\\\n",
    "You are a University Professor creating a test for advanced students. For each context, create a question that is specific to the context. Avoid creating generic or general questions.\n",
    "\n",
    "question: a question about the context.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "question\n",
    "\n",
    "context: {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template=qa_template)\n",
    "\n",
    "messages = prompt_template.format_messages(\n",
    "    context=docs[0],\n",
    "    format_instructions=format_instructions\n",
    ")\n",
    "\n",
    "question_generation_chain = bare_template | question_generation_llm\n",
    "\n",
    "response = question_generation_chain.invoke({\"content\" : messages})\n",
    "output_dict = question_output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 95,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "aKFw9kyZd7eB",
    "outputId": "bbcf9e15-58be-4899-f102-6cae59c45eb0"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question\n",
      "What role did Mrs. Indira Gandhi play in incorporating environmental protection into the Constitution of India?\n",
      "context\n",
      "Magsaysay awardee Sh. Rajender Singh known for his water conservation efforts are some such contemporary figures. Salim Ali is a renowned ornithologist, famous for his work on Indian birds. In modern India, our late Prime Minister Mrs. Indira Gandhi was instrumental in introducing the concept of environmental protection in the Constitution of India as a fundamental duty while Mrs. Maneka Gandhi, formerly environment minister, has worked a lot for the cause of wildlife protection. Citizen’s report on environment was first published by late Sh. Anil Aggarwal, the founder Chairman of Centre for Science & Environment. Even with many such key persons leading the cause to environment, India is yet to achieve a lot in this field.\n",
      "metadata\n",
      "{'source': 'env.pdf', 'page': 2, 'header': ''}\n"
     ]
    }
   ],
   "source": [
    "for k, v in output_dict.items():\n",
    "  print(k)\n",
    "  print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {
    "id": "dtASDdhLfd89"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Zolpr3CYeEYm",
    "outputId": "a7962cf2-4cdf-4c7a-b776-a0c2478042e1"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:12<00:00,  3.11s/it]\n"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "qac_triples = []\n",
    "\n",
    "for text in tqdm(docs[:10]):\n",
    "  messages = prompt_template.format_messages(\n",
    "      context=text,\n",
    "      format_instructions=format_instructions\n",
    "  )\n",
    "  response = question_generation_chain.invoke({\"content\" : messages})\n",
    "  try:\n",
    "    output_dict = question_output_parser.parse(response.content)\n",
    "  except Exception as e:\n",
    "    continue\n",
    "  output_dict[\"context\"] = text\n",
    "  qac_triples.append(output_dict)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "mKBdQHK7Y2Vw",
    "outputId": "73c7d139-be2d-483f-9f70-b6c4aae91506"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'What was the significance of the United Nations Conference on Environment and Development, held in Rio de Janeiro in 1992, and how did it contribute to international environmental awareness?',\n",
       " 'context': Document(metadata={'source': 'env.pdf', 'page': 1, 'header': ''}, page_content='Environment Calendar\\nNEED FOR PUBLIC AWARENESS\\n(a) International Efforts for Environment\\nEnvironmental issues received international attention about 35 years back in Stockholm Conference, held on 5th\\nJune, 1972. Since then we celebrate World Environment Day on 5th June. At the United Nations Conference\\non Environment and Development held at Ri o de Janeiro, in 1992, known popularly as Earth Summit, and ten\\nyears later, the World Summit on Sustainable Development, held at Johannesburg in 2002, key issues of global\\nenvironmental concern were highlighted. Attention of general public was drawn towards the deteriorating\\nenvironmental conditions all over the world.')}"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "qac_triples[2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "metadata": {
    "id": "vNB9Z2DrX2TC"
   },
   "outputs": [],
   "source": [
    "answer_generation_llm = ChatOpenAI(model=\"gpt-4o\", api_key=openai_api_key)\n",
    "\n",
    "answer_schema = ResponseSchema(\n",
    "    name=\"answer\",\n",
    "    description=\"an answer to the question\"\n",
    ")\n",
    "\n",
    "answer_response_schemas = [\n",
    "    answer_schema,\n",
    "]\n",
    "\n",
    "answer_output_parser = StructuredOutputParser.from_response_schemas(answer_response_schemas)\n",
    "format_instructions = answer_output_parser.get_format_instructions()\n",
    "\n",
    "qa_template = \"\"\"\\\n",
    "You are a University Professor creating a test for advanced students. For each question and context, create an answer.\n",
    "\n",
    "answer: a answer about the context.\n",
    "\n",
    "Format the output as JSON with the following keys:\n",
    "answer\n",
    "\n",
    "question: {question}\n",
    "context: {context}\n",
    "\"\"\"\n",
    "\n",
    "prompt_template = ChatPromptTemplate.from_template(template=qa_template)\n",
    "\n",
    "messages = prompt_template.format_messages(\n",
    "    context=qac_triples[0][\"context\"],\n",
    "    question=qac_triples[0][\"question\"],\n",
    "    format_instructions=format_instructions\n",
    ")\n",
    "\n",
    "answer_generation_chain = bare_template | answer_generation_llm\n",
    "\n",
    "response = answer_generation_chain.invoke({\"content\" : messages})\n",
    "output_dict = answer_output_parser.parse(response.content)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Rk-_lRR6fn5U",
    "outputId": "fb014a65-a56f-49be-8ecf-9ca5527aa803"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "question\n",
      "Discuss the contributions of Sh. Rajender Singh to water conservation efforts in India and how it has impacted contemporary environmental policies.\n",
      "context\n",
      "page_content='Magsaysay awardee Sh. Rajender Singh known for his water conservation efforts are some such contemporary figures. Salim Ali is a renowned ornithologist, famous for his work on Indian birds. In modern India, our late Prime Minister Mrs. Indira Gandhi was instrumental in introducing the concept of environmental protection in the Constitution of India as a fundamental duty while Mrs. Maneka Gandhi, formerly environment minister, has worked a lot for the cause of wildlife protection. Citizen’s report on environment was first published by late Sh. Anil Aggarwal, the founder Chairman of Centre for Science & Environment. Even with many such key persons leading the cause to environment, India is yet to achieve a lot in this field.' metadata={'source': 'env.pdf', 'page': 2, 'header': ''}\n",
      "answer\n",
      "Sh. Rajender Singh, a Magsaysay awardee, is renowned for his significant contributions to water conservation in India. His efforts have played a crucial role in reviving several rivers and implementing traditional water harvesting techniques, which have led to sustainable water management practices in various regions. These initiatives have inspired contemporary environmental policies that focus on community-based water conservation and management strategies, highlighting the importance of local participation and traditional knowledge in addressing water scarcity issues. Singh's work has underscored the necessity of integrating grassroots efforts with policy frameworks to ensure long-term environmental sustainability.\n"
     ]
    }
   ],
   "source": [
    "for k, v in output_dict.items():\n",
    "  print(k)\n",
    "  print(v)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "yCdH0e9rrAKd",
    "outputId": "629d8791-dedb-47c7-b5a0-adaa26f142cd"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|███████████████████████████████████████████████████████████████████████████████████████████████████████████████████████| 4/4 [00:30<00:00,  7.55s/it]\n"
     ]
    }
   ],
   "source": [
    "for triple in tqdm(qac_triples):\n",
    "  messages = prompt_template.format_messages(\n",
    "      context=triple[\"context\"],\n",
    "      question=triple[\"question\"],\n",
    "      format_instructions=format_instructions\n",
    "  )\n",
    "  response = answer_generation_chain.invoke({\"content\" : messages})\n",
    "  try:\n",
    "    output_dict = answer_output_parser.parse(response.content)\n",
    "  except Exception as e:\n",
    "    continue\n",
    "  triple[\"answer\"] = output_dict[\"answer\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {
    "id": "rrHXgH9Qs1ep"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U datasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {
    "id": "uAvGGTyXsoHQ"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from datasets import Dataset\n",
    "\n",
    "ground_truth_qac_set = pd.DataFrame(qac_triples)\n",
    "ground_truth_qac_set[\"context\"] = ground_truth_qac_set[\"context\"].map(lambda x: str(x.page_content))\n",
    "ground_truth_qac_set = ground_truth_qac_set.rename(columns={\"answer\" : \"ground_truth\"})\n",
    "\n",
    "\n",
    "eval_dataset = Dataset.from_pandas(ground_truth_qac_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "q_FHUnAPVseB",
    "outputId": "1a907389-e62b-4686-b3d7-e8707acfbd47"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context', 'ground_truth'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "W8CaCUeBVu4l",
    "outputId": "72cbf3c8-c698-4682-821a-8566f36f6adb"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'question': 'Discuss the contributions of Sh. Rajender Singh to water conservation efforts in India and how it has impacted contemporary environmental policies.',\n",
       " 'context': 'Magsaysay awardee Sh. Rajender Singh  known for his water conservation efforts are some such contemporary\\nfigures. Salim Ali  is a renowned ornithologist, famous for his work on Indian birds. In modern India, our late\\nPrime Minister Mrs. Indira Gandhi was instrumental in introducing the concept of environmental protection in\\nthe Constitution of India as a fundamental duty while Mrs. Maneka Gan dhi, formerly environment minister, has\\nworked a lot for the cause of wildlife protection. Citizen’s report on environment  was first published by late\\nSh. Anil Aggarwal , the founder Chairman of Centre for Science & Environment. Even with many such key\\npersons leading the cause to environment, India is yet to achieve a lot in this field.',\n",
       " 'ground_truth': \"Sh. Rajender Singh, a Magsaysay awardee, is renowned for his significant contributions to water conservation efforts in India. His work has played a pivotal role in reviving traditional water management systems and promoting sustainable water use practices. Singh's initiatives have influenced contemporary environmental policies by demonstrating the importance of community-led conservation efforts and the efficacy of traditional methods in addressing modern water crises. His impact is evident in the increased emphasis on water conservation in policy frameworks and the adoption of similar grassroots approaches across various regions in India.\"}"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "c4bc64d47f2e4a239cf7156e7812887d",
      "b4a71cf676584200b46922fb976d1d50",
      "65f75f3d72cd415faffb32999893738d",
      "5367cbe7ca4d43b089ff0d5d7cd17d3c",
      "31390facfbeb455fa83067fc23d30718",
      "22fc25617c664e4aa02b7457832c1bef",
      "b556054df18d47aa8cb58ac482ca31bb",
      "0fff4a6672c848a38945e19101c46168",
      "de662cb67d054f08a15d191923d40369",
      "b53ebcf672a244978391cae559db5bf2",
      "f2de6a2c1f4b4a2fa5196028c0da0754"
     ]
    },
    "id": "Nhp5X4M8zqrm",
    "outputId": "7e3c36df-12a3-4ea7-a772-dc1e0bc61568"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Creating CSV from Arrow format: 100%|██████████████████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 177.97ba/s]\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "5799"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset.to_csv(\"groundtruth_eval_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "7Al5cagr-rvL"
   },
   "source": [
    "### Evaluating RAG Pipelines\n",
    "\n",
    "If you skipped ahead and need to load the `.csv` directly - uncomment the code below.\n",
    "\n",
    "If you're using Colab to do this notebook - please ensure you add it to your session files."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 107,
   "metadata": {
    "id": "QJhes58R66-P"
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Generating train split: 4 examples [00:00, 481.27 examples/s]\n"
     ]
    }
   ],
   "source": [
    "from datasets import Dataset\n",
    "eval_dataset = Dataset.from_csv(\"groundtruth_eval_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 112,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fAD8c_kthWc",
    "outputId": "e722498d-3179-4cf1-e206-29a27163ace5"
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['question', 'context', 'ground_truth'],\n",
       "    num_rows: 4\n",
       "})"
      ]
     },
     "execution_count": 112,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "eval_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5fAD8c_kthWc",
    "outputId": "e722498d-3179-4cf1-e206-29a27163ace5"
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[NbConvertApp] Converting notebook uniquery_ragas.ipynb to script\n",
      "[NbConvertApp] Writing 25853 bytes to uniquery_ragas.py\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "IqFYbjLK-6X7"
   },
   "source": [
    "### Evaluation Using RAGAS\n",
    "\n",
    "Now we can evaluate using RAGAS!\n",
    "\n",
    "The set-up is fairly straightforward - we simply need to create a dataset with our generated answers and our contexts, and then evaluate using the framework."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {
    "id": "1eBoHaf5t4w8"
   },
   "outputs": [
    {
     "ename": "ImportError",
     "evalue": "cannot import name 'get_cache_dir' from 'ragas.utils' (/home/cr/.local/lib/python3.12/site-packages/ragas/utils.py)",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mImportError\u001b[0m                               Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[78], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      2\u001b[0m     answer_relevancy,\n\u001b[1;32m      3\u001b[0m     faithfulness,\n\u001b[1;32m      4\u001b[0m     context_recall,\n\u001b[1;32m      5\u001b[0m     context_precision,\n\u001b[1;32m      6\u001b[0m     answer_correctness,\n\u001b[1;32m      7\u001b[0m     answer_similarity\n\u001b[1;32m      8\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mcritique\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m harmfulness\n\u001b[1;32m     11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/ragas/__init__.py:1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01madaptation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m adapt\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_schema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m EvaluationDataset, MultiTurnSample, SingleTurnSample\n\u001b[1;32m      3\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mevaluation\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m evaluate\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/ragas/adaptation.py:7\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m llm_factory\n\u001b[1;32m      6\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseRagasLLM, LangchainLLMWrapper\n\u001b[0;32m----> 7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mbase\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m MetricWithLLM\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21madapt\u001b[39m(\n\u001b[1;32m     11\u001b[0m     metrics: t\u001b[38;5;241m.\u001b[39mList[MetricWithLLM],\n\u001b[1;32m     12\u001b[0m     language: \u001b[38;5;28mstr\u001b[39m,\n\u001b[1;32m     13\u001b[0m     llm: t\u001b[38;5;241m.\u001b[39mOptional[BaseRagasLLM] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     14\u001b[0m     cache_dir: t\u001b[38;5;241m.\u001b[39mOptional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m     15\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m     16\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"\u001b[39;00m\n\u001b[1;32m     17\u001b[0m \u001b[38;5;124;03m    Adapt the metric to a different language.\u001b[39;00m\n\u001b[1;32m     18\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/ragas/metrics/__init__.py:4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01minspect\u001b[39;00m\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01msys\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_answer_correctness\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnswerCorrectness, answer_correctness\n\u001b[1;32m      5\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_answer_relevance\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m      6\u001b[0m     AnswerRelevancy,\n\u001b[1;32m      7\u001b[0m     ResponseRelevancy,\n\u001b[1;32m      8\u001b[0m     answer_relevancy,\n\u001b[1;32m      9\u001b[0m )\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_answer_similarity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m (\n\u001b[1;32m     11\u001b[0m     AnswerSimilarity,\n\u001b[1;32m     12\u001b[0m     SemanticSimilarity,\n\u001b[1;32m     13\u001b[0m     answer_similarity,\n\u001b[1;32m     14\u001b[0m )\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/ragas/metrics/_answer_correctness.py:11\u001b[0m\n\u001b[1;32m      8\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic_v1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[1;32m     10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mdataset_schema\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m SingleTurnSample\n\u001b[0;32m---> 11\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01moutput_parser\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m RagasoutputParser, get_json_format_instructions\n\u001b[1;32m     12\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Prompt, PromptValue\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mmetrics\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01m_answer_similarity\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m AnswerSimilarity\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/ragas/llms/output_parser.py:10\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mlangchain_core\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mpydantic_v1\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseModel\n\u001b[1;32m      9\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseRagasLLM\n\u001b[0;32m---> 10\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mprompt\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m Prompt, PromptValue\n\u001b[1;32m     12\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n\u001b[1;32m     13\u001b[0m \u001b[38;5;66;03m# The get_format_instructions function is a modified version from\u001b[39;00m\n\u001b[1;32m     14\u001b[0m \u001b[38;5;66;03m# langchain_core.output_parser.pydantic. The original version removed the \"type\" json schema\u001b[39;00m\n\u001b[1;32m     15\u001b[0m \u001b[38;5;66;03m# property that confused some older LLMs.\u001b[39;00m\n",
      "File \u001b[0;32m~/.local/lib/python3.12/site-packages/ragas/llms/prompt.py:15\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m BaseRagasLLM\n\u001b[1;32m     14\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mllms\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mjson_load\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m json_loader\n\u001b[0;32m---> 15\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mragas\u001b[39;00m\u001b[38;5;21;01m.\u001b[39;00m\u001b[38;5;21;01mutils\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m get_cache_dir\n\u001b[1;32m     17\u001b[0m Example \u001b[38;5;241m=\u001b[39m t\u001b[38;5;241m.\u001b[39mDict[\u001b[38;5;28mstr\u001b[39m, t\u001b[38;5;241m.\u001b[39mAny]\n\u001b[1;32m     19\u001b[0m logger \u001b[38;5;241m=\u001b[39m logging\u001b[38;5;241m.\u001b[39mgetLogger(\u001b[38;5;18m__name__\u001b[39m)\n",
      "\u001b[0;31mImportError\u001b[0m: cannot import name 'get_cache_dir' from 'ragas.utils' (/home/cr/.local/lib/python3.12/site-packages/ragas/utils.py)"
     ]
    }
   ],
   "source": [
    "from ragas.metrics import (\n",
    "    answer_relevancy,\n",
    "    faithfulness,\n",
    "    context_recall,\n",
    "    context_precision,\n",
    "    answer_correctness,\n",
    "    answer_similarity\n",
    ")\n",
    "\n",
    "from ragas.metrics.critique import harmfulness\n",
    "from ragas import evaluate\n",
    "\n",
    "def create_ragas_dataset(rag_pipeline, eval_dataset):\n",
    "  rag_dataset = []\n",
    "  for row in tqdm(eval_dataset):\n",
    "    answer = rag_pipeline.invoke({\"question\" : row[\"question\"]})\n",
    "    rag_dataset.append(\n",
    "        {\"question\" : row[\"question\"],\n",
    "         \"answer\" : answer[\"response\"].content,\n",
    "         \"contexts\" : [context.page_content for context in answer[\"context\"]],\n",
    "         \"ground_truths\" : [row[\"ground_truth\"]]\n",
    "         }\n",
    "    )\n",
    "  rag_df = pd.DataFrame(rag_dataset)\n",
    "  rag_eval_dataset = Dataset.from_pandas(rag_df)\n",
    "  return rag_eval_dataset\n",
    "\n",
    "def evaluate_ragas_dataset(ragas_dataset):\n",
    "  result = evaluate(\n",
    "    ragas_dataset,\n",
    "    metrics=[\n",
    "        context_precision,\n",
    "        faithfulness,\n",
    "        answer_relevancy,\n",
    "        context_recall,\n",
    "        answer_correctness,\n",
    "        answer_similarity\n",
    "    ],\n",
    "  )\n",
    "  return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "J4c4Jd8G_lXY"
   },
   "source": [
    "Lets create our dataset first:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "R7oXgcjkuopO",
    "outputId": "6db1a904-90a2-4e47-85da-a442ebdc56b1"
   },
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'create_ragas_dataset' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[61], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;28;01mfrom\u001b[39;00m \u001b[38;5;21;01mtqdm\u001b[39;00m \u001b[38;5;28;01mimport\u001b[39;00m tqdm\n\u001b[1;32m      2\u001b[0m \u001b[38;5;28;01mimport\u001b[39;00m \u001b[38;5;21;01mpandas\u001b[39;00m \u001b[38;5;28;01mas\u001b[39;00m \u001b[38;5;21;01mpd\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m basic_qa_ragas_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mcreate_ragas_dataset\u001b[49m(retrieval_augmented_qa_chain, eval_dataset)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'create_ragas_dataset' is not defined"
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "import pandas as pd\n",
    "\n",
    "basic_qa_ragas_dataset = create_ragas_dataset(retrieval_augmented_qa_chain, eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "nfzaFWEMZ5l_",
    "outputId": "60ca3e05-209a-4375-f24c-a23ad06e525e"
   },
   "outputs": [],
   "source": [
    "basic_qa_ragas_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "8Vv1NsRGZ6m5",
    "outputId": "2ef4fbd9-011e-42b7-88d9-11c79974d87e"
   },
   "outputs": [],
   "source": [
    "basic_qa_ragas_dataset[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Obbgw3im_n01"
   },
   "source": [
    "Save it for later:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "86761a36bdb04fed9f1dae6e74da54ce",
      "e079c0eb3d9c4ae3a40491f059a864f7",
      "d4bde97f3895450782030cad7808ea59",
      "1d17b8847ab34a1d8fc79430e8b64a12",
      "fb953d8d116e4cc389dbc23a0055873f",
      "bf27f78edb15477492fb2d5dd8dc5137",
      "ee96a569b8a54944bcac1b1bc164e53e",
      "e556e254882340168833ecf1a7153a90",
      "c077837b8b044c2fb14dcd8fbc44a37b",
      "e5c8b5933c754a1192456f43682276c5",
      "84abf77081a04bb686f794b49e04761d"
     ]
    },
    "id": "6FG8x4i3yZ2B",
    "outputId": "52eb909f-69be-4c80-d9bc-77c2842bf14d"
   },
   "outputs": [],
   "source": [
    "basic_qa_ragas_dataset.to_csv(\"uniquery_ragas_dataset.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "A5I_d_RT_pFr"
   },
   "source": [
    "And finally - evaluate how it did!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "ywp3Rwavy9pc",
    "outputId": "7a3948ce-b743-4d95-a581-17e035215f3f"
   },
   "outputs": [],
   "source": [
    "basic_qa_result = evaluate_ragas_dataset(basic_qa_ragas_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "m4oYnKTn15gY",
    "outputId": "ba48e4d2-5559-4748-8bc6-0101074a5c0e"
   },
   "outputs": [],
   "source": [
    "basic_qa_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "SwhBxlxYAdno"
   },
   "source": [
    "### Testing Other Retrievers\n",
    "\n",
    "Now we can test our how changing our Retriever impacts our RAGAS evaluation!\n",
    "\n",
    "We'll build this simple qa_chain factory to create standardized qa_chains where the only different component will be the retriever."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "qnfy4VNkzZi2"
   },
   "outputs": [],
   "source": [
    "def create_qa_chain(retriever):\n",
    "  primary_qa_llm = ChatOpenAI(model_name=\"gpt-3.5-turbo\", temperature=0)\n",
    "  created_qa_chain = (\n",
    "    {\"context\": itemgetter(\"question\") | retriever,\n",
    "     \"question\": itemgetter(\"question\")\n",
    "    }\n",
    "    | RunnablePassthrough.assign(\n",
    "        context=itemgetter(\"context\")\n",
    "      )\n",
    "    | {\n",
    "         \"response\": prompt | primary_qa_llm,\n",
    "         \"context\": itemgetter(\"context\"),\n",
    "      }\n",
    "  )\n",
    "\n",
    "  return created_qa_chain"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vOPp4Xq7AvEx"
   },
   "source": [
    "#### Parent Document Retriever\n",
    "\n",
    "One of the easier ways we can imagine improving a retriever is to embed our documents into small chunks, and then retrieve a significant amount of additional context that \"surrounds\" the found context.\n",
    "\n",
    "You can read more about this method [here](https://python.langchain.com/docs/modules/data_connection/retrievers/parent_document_retriever)!\n",
    "\n",
    "The basic outline of this retrieval method is as follows:\n",
    "\n",
    "1. Obtain User Question\n",
    "2. Retrieve child documents using Dense Vector Retrieval\n",
    "3. Merge the child documents based on their parents. If they have the same parents - they become merged.\n",
    "4. Replace the child documents with their respective parent documents from an in-memory-store.\n",
    "5. Use the parent documents to augment generation."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "67I6QJAJ0Un7"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import ParentDocumentRetriever\n",
    "from langchain.storage import InMemoryStore\n",
    "\n",
    "parent_splitter = RecursiveCharacterTextSplitter(chunk_size=1500)\n",
    "child_splitter = RecursiveCharacterTextSplitter(chunk_size=200)\n",
    "\n",
    "vectorstore = Chroma(collection_name=\"split_parents\", embedding_function=OpenAIEmbeddings())\n",
    "\n",
    "store = InMemoryStore()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zfk5RYUt00Pw"
   },
   "outputs": [],
   "source": [
    "parent_document_retriever = ParentDocumentRetriever(\n",
    "    vectorstore=vectorstore,\n",
    "    docstore=store,\n",
    "    child_splitter=child_splitter,\n",
    "    parent_splitter=parent_splitter,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "68c1t4o104AK"
   },
   "outputs": [],
   "source": [
    "parent_document_retriever.add_documents(base_docs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MTH0MDolBndm"
   },
   "source": [
    "Let's create, test, and then evaluate our new chain!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "KMjLfqOC09Iw"
   },
   "outputs": [],
   "source": [
    "parent_document_retriever_qa_chain = create_qa_chain(parent_document_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "Rv8bAHPN1H4P",
    "outputId": "faa6bf43-1604-4468-9faf-bbefd8e48281"
   },
   "outputs": [],
   "source": [
    "parent_document_retriever_qa_chain.invoke({\"question\" : \"What is RAG?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "OQJRIQmU1WTw",
    "outputId": "295a9011-684d-4c38-e409-867022603608"
   },
   "outputs": [],
   "source": [
    "pdr_qa_ragas_dataset = create_ragas_dataset(parent_document_retriever_qa_chain, eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "bf7f045bdbe24360ad2aa2f4c8f02e79",
      "761e3c6035bf49429b3035145451d2df",
      "ffb7c97e7af648aaa13a43427154140e",
      "95d92c5c74e845779337eb727c2bbfc0",
      "6e7fb9a1d1454fcd9bcf5b5f748fb975",
      "207785da1f404d6ea0e8c63655a7aa51",
      "71237d176b2c4138a5e0346d10482257",
      "ed457547dc154f6bbce4ec970bb09c76",
      "c9f479f81119450bb451d5830361467c",
      "56098a347ea94ea3b10bd8d2ec0d4288",
      "7940d9e3f5fa4592b58dec3fdb55595a"
     ]
    },
    "id": "d9vfKnCL1jtB",
    "outputId": "1d7421a8-b564-4da3-cd74-d1eb3f8311f7"
   },
   "outputs": [],
   "source": [
    "pdr_qa_ragas_dataset.to_csv(\"pdr_qa_ragas_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "qfB1H9S_1mW3",
    "outputId": "426d7b1b-2b0c-40d3-e7d7-39da43363f06"
   },
   "outputs": [],
   "source": [
    "pdr_qa_result = evaluate_ragas_dataset(pdr_qa_ragas_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5nFyYCdL2Nco",
    "outputId": "bdde7173-c649-40bc-cbc3-e38a70c9f50a"
   },
   "outputs": [],
   "source": [
    "pdr_qa_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JaNk6o7_BqX8"
   },
   "source": [
    "#### Ensemble Retrieval\n",
    "\n",
    "Next let's look at ensemble retrieval!\n",
    "\n",
    "You can read more about this [here](https://python.langchain.com/docs/modules/data_connection/retrievers/ensemble)!\n",
    "\n",
    "The basic idea is as follows:\n",
    "\n",
    "1. Obtain User Question\n",
    "2. Hit the Retriever Pair\n",
    "    - Retrieve Documents with BM25 Sparse Vector Retrieval\n",
    "    - Retrieve Documents with Dense Vector Retrieval Method\n",
    "3. Collect and \"fuse\" the retrieved docs based on their weighting using the [Reciprocal Rank Fusion](https://plg.uwaterloo.ca/~gvcormac/cormacksigir09-rrf.pdf) algorithm into a single ranked list.\n",
    "4. Use those documents to augment our generation.\n",
    "\n",
    "Ensure your `weights` list - the relative weighting of each retriever - sums to 1!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "zz7dl1GD5-L-"
   },
   "outputs": [],
   "source": [
    "!pip install -q -U rank_bm25"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Vs8wxT9b5pRA"
   },
   "outputs": [],
   "source": [
    "from langchain.retrievers import BM25Retriever, EnsembleRetriever\n",
    "\n",
    "text_splitter = RecursiveCharacterTextSplitter(chunk_size=450, chunk_overlap=75)\n",
    "docs = text_splitter.split_documents(base_docs)\n",
    "\n",
    "bm25_retriever = BM25Retriever.from_documents(docs)\n",
    "bm25_retriever.k = 2\n",
    "\n",
    "embedding = OpenAIEmbeddings()\n",
    "vectorstore = Chroma.from_documents(docs, embedding)\n",
    "chroma_retriever = vectorstore.as_retriever(search_kwargs={\"k\": 3})\n",
    "\n",
    "ensemble_retriever = EnsembleRetriever(retrievers=[bm25_retriever, chroma_retriever], weights=[0.75, 0.25])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "cv69YDpF6PrJ"
   },
   "outputs": [],
   "source": [
    "ensemble_retriever_qa_chain = create_qa_chain(ensemble_retriever)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 35
    },
    "id": "6lSszzrf6UmP",
    "outputId": "8a5893d5-4095-42e5-aecf-66d849512321"
   },
   "outputs": [],
   "source": [
    "ensemble_retriever_qa_chain.invoke({\"question\" : \"What is RAG?\"})[\"response\"].content"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "abUgTGDT6UrV",
    "outputId": "749ae6db-75b9-48a7-e743-a8aecdcbd802"
   },
   "outputs": [],
   "source": [
    "ensemble_qa_ragas_dataset = create_ragas_dataset(ensemble_retriever_qa_chain, eval_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 66,
     "referenced_widgets": [
      "632135599e39470aac1a3bb3d3de0ca4",
      "567176b50d074a1c9d384a8df8c3ff4c",
      "6bfa39f2c84e4f08b5ffb9a416398824",
      "911b40169865413b98643789150e5495",
      "2add9d30edd84152bb6d7bfa4ed2d910",
      "f34ffd11b98045b9bae326dd48a54896",
      "e3e19fc9963c4bf39293bda7c2030d5a",
      "c15c27b0523a429e9d77f439d47ada90",
      "256a0dbb2f104d928e181d2a882a9867",
      "68790cfe4ea14fc4a63275f3e99c468f",
      "e7df092ac205443e8baa3646ff1eae5b"
     ]
    },
    "id": "bGHipYsf7phk",
    "outputId": "a70b0d3e-870f-49b8-a16a-5b7d4623c33f"
   },
   "outputs": [],
   "source": [
    "ensemble_qa_ragas_dataset.to_csv(\"ensemble_qa_ragas_dataset.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ozo0jkvx7r1d",
    "outputId": "f5770c52-4614-4172-8834-d48bd4005218"
   },
   "outputs": [],
   "source": [
    "ensemble_qa_result = evaluate_ragas_dataset(ensemble_qa_ragas_dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "hvabdcbh793a",
    "outputId": "56daa44b-841b-4924-9242-77c2bc93f86e"
   },
   "outputs": [],
   "source": [
    "ensemble_qa_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "O4vXVWqiCcSI"
   },
   "source": [
    "### Conclusion\n",
    "\n",
    "Observe your results in a table!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "PmBoVQ5hV3Kc",
    "outputId": "12196187-5cbf-40b2-f35f-ab45616e71a4"
   },
   "outputs": [],
   "source": [
    "basic_qa_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Ax1JLXKxUsXF",
    "outputId": "b83ba792-7e66-44ff-b219-0f3890a5fe8b"
   },
   "outputs": [],
   "source": [
    "pdr_qa_result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "drxLlO3zUpyQ",
    "outputId": "3b595607-2fa5-4590-d2e6-9707aa7bb283"
   },
   "outputs": [],
   "source": [
    "ensemble_qa_result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "r6YPGf-2l0Kx"
   },
   "source": [
    "We can also zoom in on each result and find specific information about each of the questions and answers."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "SkxLtk43ikka"
   },
   "outputs": [],
   "source": [
    "ensemble_qa_result_df = ensemble_qa_result.to_pandas()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 1000
    },
    "id": "3JZMhUg3jSvE",
    "outputId": "95d1cf44-88ee-4056-b698-64237b119fe0"
   },
   "outputs": [],
   "source": [
    "ensemble_qa_result_df"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0jXR7ckel-v8"
   },
   "source": [
    "We'll also look at combining the results and looking at them in a single table so we can make inferences about them!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BE5KKE_JkcD3"
   },
   "outputs": [],
   "source": [
    "def create_df_dict(pipeline_name, pipeline_items):\n",
    "  df_dict = {\"name\" : pipeline_name}\n",
    "  for name, score in pipeline_items:\n",
    "    df_dict[name] = score\n",
    "  return df_dict"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "L1mPqYdqk4iQ"
   },
   "outputs": [],
   "source": [
    "basic_rag_df_dict = create_df_dict(\"basic_rag\", basic_qa_result.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "ntJPzwy9lI46"
   },
   "outputs": [],
   "source": [
    "pdr_rag_df_dict = create_df_dict(\"pdr_rag\", pdr_qa_result.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "R0fkbIQElPza"
   },
   "outputs": [],
   "source": [
    "ensemble_rag_df_dict = create_df_dict(\"ensemble_rag\", ensemble_qa_result.items())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Bc4T1E83lVbE"
   },
   "outputs": [],
   "source": [
    "results_df = pd.DataFrame([basic_rag_df_dict, pdr_rag_df_dict, ensemble_rag_df_dict])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 163
    },
    "id": "cv_9wNYGlibg",
    "outputId": "6580c17c-543a-4d54-8577-104c0173f368"
   },
   "outputs": [],
   "source": [
    "results_df.sort_values(\"answer_correctness\", ascending=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "YPocfrNFiYWi"
   },
   "source": [
    "### ❓QUESTION❓\n",
    "\n",
    "What conclusions can you draw about the above results?\n",
    "\n",
    "Describe in your own words what the metrics are expressing."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "fbhz-vD4JPtN"
   },
   "outputs": [],
   "source": [
    "retrieval_augmented_qa_chain = (\n",
    "    RunnableParallel({\n",
    "        'context': itemgetter('question') | base_retriever,\n",
    "        'question': RunnablePassthrough()\n",
    "    }) | {\n",
    "        'response': prompt | primary_qa_llm | parser,\n",
    "        'context': itemgetter('context')\n",
    "    }\n",
    ")"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.6"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "0fff4a6672c848a38945e19101c46168": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "1d17b8847ab34a1d8fc79430e8b64a12": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e5c8b5933c754a1192456f43682276c5",
      "placeholder": "​",
      "style": "IPY_MODEL_84abf77081a04bb686f794b49e04761d",
      "value": " 1/1 [00:00&lt;00:00, 35.79ba/s]"
     }
    },
    "207785da1f404d6ea0e8c63655a7aa51": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "22fc25617c664e4aa02b7457832c1bef": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "256a0dbb2f104d928e181d2a882a9867": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "2add9d30edd84152bb6d7bfa4ed2d910": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "31390facfbeb455fa83067fc23d30718": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "5367cbe7ca4d43b089ff0d5d7cd17d3c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_b53ebcf672a244978391cae559db5bf2",
      "placeholder": "​",
      "style": "IPY_MODEL_f2de6a2c1f4b4a2fa5196028c0da0754",
      "value": " 1/1 [00:00&lt;00:00, 18.79ba/s]"
     }
    },
    "56098a347ea94ea3b10bd8d2ec0d4288": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "567176b50d074a1c9d384a8df8c3ff4c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_f34ffd11b98045b9bae326dd48a54896",
      "placeholder": "​",
      "style": "IPY_MODEL_e3e19fc9963c4bf39293bda7c2030d5a",
      "value": "Creating CSV from Arrow format: 100%"
     }
    },
    "632135599e39470aac1a3bb3d3de0ca4": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_567176b50d074a1c9d384a8df8c3ff4c",
       "IPY_MODEL_6bfa39f2c84e4f08b5ffb9a416398824",
       "IPY_MODEL_911b40169865413b98643789150e5495"
      ],
      "layout": "IPY_MODEL_2add9d30edd84152bb6d7bfa4ed2d910"
     }
    },
    "65f75f3d72cd415faffb32999893738d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_0fff4a6672c848a38945e19101c46168",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_de662cb67d054f08a15d191923d40369",
      "value": 1
     }
    },
    "68790cfe4ea14fc4a63275f3e99c468f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "6bfa39f2c84e4f08b5ffb9a416398824": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_c15c27b0523a429e9d77f439d47ada90",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_256a0dbb2f104d928e181d2a882a9867",
      "value": 1
     }
    },
    "6e7fb9a1d1454fcd9bcf5b5f748fb975": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "71237d176b2c4138a5e0346d10482257": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "761e3c6035bf49429b3035145451d2df": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_207785da1f404d6ea0e8c63655a7aa51",
      "placeholder": "​",
      "style": "IPY_MODEL_71237d176b2c4138a5e0346d10482257",
      "value": "Creating CSV from Arrow format: 100%"
     }
    },
    "7940d9e3f5fa4592b58dec3fdb55595a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "84abf77081a04bb686f794b49e04761d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "86761a36bdb04fed9f1dae6e74da54ce": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_e079c0eb3d9c4ae3a40491f059a864f7",
       "IPY_MODEL_d4bde97f3895450782030cad7808ea59",
       "IPY_MODEL_1d17b8847ab34a1d8fc79430e8b64a12"
      ],
      "layout": "IPY_MODEL_fb953d8d116e4cc389dbc23a0055873f"
     }
    },
    "911b40169865413b98643789150e5495": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_68790cfe4ea14fc4a63275f3e99c468f",
      "placeholder": "​",
      "style": "IPY_MODEL_e7df092ac205443e8baa3646ff1eae5b",
      "value": " 1/1 [00:00&lt;00:00, 33.41ba/s]"
     }
    },
    "95d92c5c74e845779337eb727c2bbfc0": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_56098a347ea94ea3b10bd8d2ec0d4288",
      "placeholder": "​",
      "style": "IPY_MODEL_7940d9e3f5fa4592b58dec3fdb55595a",
      "value": " 1/1 [00:00&lt;00:00, 33.86ba/s]"
     }
    },
    "b4a71cf676584200b46922fb976d1d50": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_22fc25617c664e4aa02b7457832c1bef",
      "placeholder": "​",
      "style": "IPY_MODEL_b556054df18d47aa8cb58ac482ca31bb",
      "value": "Creating CSV from Arrow format: 100%"
     }
    },
    "b53ebcf672a244978391cae559db5bf2": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "b556054df18d47aa8cb58ac482ca31bb": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "bf27f78edb15477492fb2d5dd8dc5137": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "bf7f045bdbe24360ad2aa2f4c8f02e79": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_761e3c6035bf49429b3035145451d2df",
       "IPY_MODEL_ffb7c97e7af648aaa13a43427154140e",
       "IPY_MODEL_95d92c5c74e845779337eb727c2bbfc0"
      ],
      "layout": "IPY_MODEL_6e7fb9a1d1454fcd9bcf5b5f748fb975"
     }
    },
    "c077837b8b044c2fb14dcd8fbc44a37b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "c15c27b0523a429e9d77f439d47ada90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "c4bc64d47f2e4a239cf7156e7812887d": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HBoxModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HBoxModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HBoxView",
      "box_style": "",
      "children": [
       "IPY_MODEL_b4a71cf676584200b46922fb976d1d50",
       "IPY_MODEL_65f75f3d72cd415faffb32999893738d",
       "IPY_MODEL_5367cbe7ca4d43b089ff0d5d7cd17d3c"
      ],
      "layout": "IPY_MODEL_31390facfbeb455fa83067fc23d30718"
     }
    },
    "c9f479f81119450bb451d5830361467c": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "d4bde97f3895450782030cad7808ea59": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_e556e254882340168833ecf1a7153a90",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c077837b8b044c2fb14dcd8fbc44a37b",
      "value": 1
     }
    },
    "de662cb67d054f08a15d191923d40369": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "ProgressStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "ProgressStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "bar_color": null,
      "description_width": ""
     }
    },
    "e079c0eb3d9c4ae3a40491f059a864f7": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "HTMLModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "HTMLModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "HTMLView",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_bf27f78edb15477492fb2d5dd8dc5137",
      "placeholder": "​",
      "style": "IPY_MODEL_ee96a569b8a54944bcac1b1bc164e53e",
      "value": "Creating CSV from Arrow format: 100%"
     }
    },
    "e3e19fc9963c4bf39293bda7c2030d5a": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "e556e254882340168833ecf1a7153a90": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e5c8b5933c754a1192456f43682276c5": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "e7df092ac205443e8baa3646ff1eae5b": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "ed457547dc154f6bbce4ec970bb09c76": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ee96a569b8a54944bcac1b1bc164e53e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f2de6a2c1f4b4a2fa5196028c0da0754": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "DescriptionStyleModel",
     "state": {
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "DescriptionStyleModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "StyleView",
      "description_width": ""
     }
    },
    "f34ffd11b98045b9bae326dd48a54896": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "fb953d8d116e4cc389dbc23a0055873f": {
     "model_module": "@jupyter-widgets/base",
     "model_module_version": "1.2.0",
     "model_name": "LayoutModel",
     "state": {
      "_model_module": "@jupyter-widgets/base",
      "_model_module_version": "1.2.0",
      "_model_name": "LayoutModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/base",
      "_view_module_version": "1.2.0",
      "_view_name": "LayoutView",
      "align_content": null,
      "align_items": null,
      "align_self": null,
      "border": null,
      "bottom": null,
      "display": null,
      "flex": null,
      "flex_flow": null,
      "grid_area": null,
      "grid_auto_columns": null,
      "grid_auto_flow": null,
      "grid_auto_rows": null,
      "grid_column": null,
      "grid_gap": null,
      "grid_row": null,
      "grid_template_areas": null,
      "grid_template_columns": null,
      "grid_template_rows": null,
      "height": null,
      "justify_content": null,
      "justify_items": null,
      "left": null,
      "margin": null,
      "max_height": null,
      "max_width": null,
      "min_height": null,
      "min_width": null,
      "object_fit": null,
      "object_position": null,
      "order": null,
      "overflow": null,
      "overflow_x": null,
      "overflow_y": null,
      "padding": null,
      "right": null,
      "top": null,
      "visibility": null,
      "width": null
     }
    },
    "ffb7c97e7af648aaa13a43427154140e": {
     "model_module": "@jupyter-widgets/controls",
     "model_module_version": "1.5.0",
     "model_name": "FloatProgressModel",
     "state": {
      "_dom_classes": [],
      "_model_module": "@jupyter-widgets/controls",
      "_model_module_version": "1.5.0",
      "_model_name": "FloatProgressModel",
      "_view_count": null,
      "_view_module": "@jupyter-widgets/controls",
      "_view_module_version": "1.5.0",
      "_view_name": "ProgressView",
      "bar_style": "success",
      "description": "",
      "description_tooltip": null,
      "layout": "IPY_MODEL_ed457547dc154f6bbce4ec970bb09c76",
      "max": 1,
      "min": 0,
      "orientation": "horizontal",
      "style": "IPY_MODEL_c9f479f81119450bb451d5830361467c",
      "value": 1
     }
    }
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
